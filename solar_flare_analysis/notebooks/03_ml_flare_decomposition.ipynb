{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc76147",
   "metadata": {},
   "source": [
    "# Solar Flare Analysis: ML-Based Flare Decomposition\n",
    "\n",
    "This notebook demonstrates how to train and use a neural network model to separate overlapping solar flares.\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0187e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add the project root to the path\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import project modules\n",
    "from config import settings\n",
    "from src.data_processing.data_loader import load_goes_data, preprocess_xrs_data\n",
    "from src.flare_detection.traditional_detection import (\n",
    "    detect_flare_peaks, define_flare_bounds, detect_overlapping_flares\n",
    ")\n",
    "from src.ml_models.flare_decomposition import (\n",
    "    FlareDecompositionModel, reconstruct_flares\n",
    ")\n",
    "from src.visualization.plotting import plot_flare_decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0999888a",
   "metadata": {},
   "source": [
    "## Understanding the ML Model Architecture\n",
    "\n",
    "Our flare decomposition model is designed to take a time series containing overlapping flares as input and separate it into individual flare components. The model uses a encoder-decoder architecture with LSTM layers to handle the temporal nature of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = FlareDecompositionModel(\n",
    "    sequence_length=settings.ML_PARAMS['sequence_length'],\n",
    "    n_features=settings.ML_PARAMS['n_features'],\n",
    "    max_flares=settings.ML_PARAMS['max_flares'],\n",
    "    dropout_rate=settings.ML_PARAMS['dropout_rate']\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model.build_model()\n",
    "\n",
    "# Print model summary\n",
    "model.model.summary()\n",
    "\n",
    "# Display the model architecture\n",
    "from keras.utils import plot_model\n",
    "try:\n",
    "    plot_model(model.model, to_file='model_architecture.png', show_shapes=True, show_dtype=True)\n",
    "    from IPython.display import Image\n",
    "    Image('model_architecture.png')\n",
    "except Exception as e:\n",
    "    print(f\"Couldn't generate model visualization: {e}\")\n",
    "    print(\"You may need to install graphviz and pydot packages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ba86a",
   "metadata": {},
   "source": [
    "## Generating Synthetic Training Data\n",
    "\n",
    "Since labeled data for overlapping solar flares is rare, we'll generate synthetic data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7097aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "X_train, y_train = model.generate_synthetic_data(n_samples=1000, noise_level=0.05)\n",
    "X_val, y_val = model.generate_synthetic_data(n_samples=200, noise_level=0.05)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Visualize a few synthetic examples\n",
    "n_examples = 3\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Original combined signal\n",
    "    plt.subplot(n_examples, 2, i*2 + 1)\n",
    "    plt.plot(X_train[i, :, 0])\n",
    "    plt.title(f'Example {i+1}: Combined Signal')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Individual components\n",
    "    plt.subplot(n_examples, 2, i*2 + 2)\n",
    "    for j in range(y_train.shape[2]):\n",
    "        plt.plot(y_train[i, :, j], label=f'Flare {j+1}')\n",
    "    plt.title(f'Example {i+1}: Individual Flares')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf3ee7",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now let's train our model on the synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.train(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=settings.ML_PARAMS['epochs'],\n",
    "    batch_size=settings.ML_PARAMS['batch_size'],\n",
    "    save_path=os.path.join(settings.MODEL_DIR, 'flare_decomposition_model')\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "history_fig = model.plot_training_history()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b890a4b",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "Let's evaluate our model on a separate test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "X_test, y_test = model.generate_synthetic_data(n_samples=100, noise_level=0.08)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {eval_results[0]:.4f}\")\n",
    "print(f\"Test MAE: {eval_results[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e174f",
   "metadata": {},
   "source": [
    "## Visualizing Model Predictions\n",
    "\n",
    "Let's see how well our model can decompose overlapping flares on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions\n",
    "predictions = model.model.predict(X_test)\n",
    "\n",
    "# Visualize predictions for a few examples\n",
    "n_examples = 3\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i in range(n_examples):\n",
    "    # Original signal\n",
    "    plt.subplot(n_examples, 3, i*3 + 1)\n",
    "    plt.plot(X_test[i, :, 0])\n",
    "    plt.title(f'Example {i+1}: Original Signal')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Ground truth individual components\n",
    "    plt.subplot(n_examples, 3, i*3 + 2)\n",
    "    for j in range(y_test.shape[2]):\n",
    "        plt.plot(y_test[i, :, j], label=f'True Flare {j+1}')\n",
    "    plt.title(f'Example {i+1}: True Components')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Predicted individual components\n",
    "    plt.subplot(n_examples, 3, i*3 + 3)\n",
    "    for j in range(predictions.shape[2]):\n",
    "        plt.plot(predictions[i, :, j], linestyle='--', label=f'Predicted Flare {j+1}')\n",
    "    plt.title(f'Example {i+1}: Predicted Components')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afadfd7",
   "metadata": {},
   "source": [
    "## Working with Real Data\n",
    "\n",
    "Now let's apply our model to real GOES XRS data to separate overlapping flares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5754a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate and load sample data\n",
    "data_dir = settings.DATA_DIR\n",
    "sample_files = [f for f in os.listdir(data_dir) if f.endswith('.nc')]\n",
    "\n",
    "if sample_files:\n",
    "    data_file = os.path.join(data_dir, sample_files[0])\n",
    "    print(f\"Using {data_file} for demonstration\")\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    data = load_goes_data(data_file)\n",
    "    channel = 'B'\n",
    "    flux_col = f'xrs{channel.lower()}'\n",
    "    df = preprocess_xrs_data(data, channel=channel, remove_bad_data=True, interpolate_gaps=True)\n",
    "    \n",
    "    # Detect flares using traditional method\n",
    "    peaks = detect_flare_peaks(\n",
    "        df, flux_col,\n",
    "        threshold_factor=settings.DETECTION_PARAMS['threshold_factor'],\n",
    "        window_size=settings.DETECTION_PARAMS['window_size']\n",
    "    )\n",
    "    \n",
    "    flares = define_flare_bounds(\n",
    "        df, flux_col, peaks['peak_index'].values,\n",
    "        start_threshold=settings.DETECTION_PARAMS['start_threshold'],\n",
    "        end_threshold=settings.DETECTION_PARAMS['end_threshold'],\n",
    "        min_duration=settings.DETECTION_PARAMS['min_duration'],\n",
    "        max_duration=settings.DETECTION_PARAMS['max_duration']\n",
    "    )\n",
    "    \n",
    "    # Detect overlapping flares\n",
    "    overlapping = detect_overlapping_flares(flares, min_overlap='2min')\n",
    "    \n",
    "    print(f\"Detected {len(overlapping)} potentially overlapping flare pairs\")\n",
    "    \n",
    "    # Process overlapping flares\n",
    "    if overlapping:\n",
    "        print(\"\\nOverlapping flare pairs:\")\n",
    "        for i, j, duration in overlapping:\n",
    "            print(f\"  Flares {i+1} and {j+1} overlap by {duration}\")\n",
    "            \n",
    "            # Extract the time series segment\n",
    "            start_idx = min(flares.iloc[i]['start_index'], flares.iloc[j]['start_index'])\n",
    "            end_idx = max(flares.iloc[i]['end_index'], flares.iloc[j]['end_index'])\n",
    "            \n",
    "            # Ensure we have enough context around the flares\n",
    "            padding = settings.ML_PARAMS['sequence_length'] // 4\n",
    "            start_idx = max(0, start_idx - padding)\n",
    "            end_idx = min(len(df) - 1, end_idx + padding)\n",
    "            \n",
    "            # Extract the time series segment\n",
    "            segment = df.iloc[start_idx:end_idx][flux_col].values\n",
    "            \n",
    "            # Ensure the segment has the right length\n",
    "            if len(segment) < settings.ML_PARAMS['sequence_length']:\n",
    "                segment = np.pad(segment, \n",
    "                                (0, settings.ML_PARAMS['sequence_length'] - len(segment)), \n",
    "                                'constant')\n",
    "            elif len(segment) > settings.ML_PARAMS['sequence_length']:\n",
    "                segment = segment[:settings.ML_PARAMS['sequence_length']]\n",
    "            \n",
    "            # Reshape for model input\n",
    "            segment = segment.reshape(1, -1, 1)\n",
    "            \n",
    "            # Decompose the flares\n",
    "            original, individual_flares, combined = reconstruct_flares(\n",
    "                model, segment, window_size=settings.ML_PARAMS['sequence_length'], plot=False\n",
    "            )\n",
    "            \n",
    "            # Plot the decomposition\n",
    "            timestamps = df.index[start_idx:start_idx+len(segment.flatten())]\n",
    "            fig = plot_flare_decomposition(original.flatten(), individual_flares, timestamps)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Calculate energy for each separated flare\n",
    "            print(\"\\nEnergy estimates for separated flares:\")\n",
    "            for k in range(individual_flares.shape[1]):\n",
    "                if np.max(individual_flares[:, k]) > 0.05 * np.max(original):\n",
    "                    energy = np.trapz(individual_flares[:, k])\n",
    "                    print(f\"  Flare component {k+1}: {energy:.4e}\")\n",
    "    else:\n",
    "        print(\"No overlapping flares detected in the data.\")\n",
    "else:\n",
    "    print(\"No .nc files found. Please place GOES XRS data in the 'data' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757dcfd",
   "metadata": {},
   "source": [
    "## Saving and Loading Models\n",
    "\n",
    "For future use, you might want to save the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bac109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = os.path.join(settings.MODEL_DIR, 'flare_decomposition_notebook')\n",
    "model.save_model(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# To load the model later\n",
    "new_model = FlareDecompositionModel(\n",
    "    sequence_length=settings.ML_PARAMS['sequence_length'],\n",
    "    n_features=settings.ML_PARAMS['n_features'],\n",
    "    max_flares=settings.ML_PARAMS['max_flares']\n",
    ")\n",
    "new_model.build_model()\n",
    "\n",
    "try:\n",
    "    new_model.load_model(model_path)\n",
    "    print(\"Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45dc3a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've demonstrated:\n",
    "\n",
    "1. How to build a neural network model for separating overlapping solar flares\n",
    "2. Generating synthetic training data for model training\n",
    "3. Training and evaluating the flare decomposition model\n",
    "4. Applying the trained model to real GOES XRS data to separate overlapping flares\n",
    "5. Saving and loading the trained model for future use\n",
    "\n",
    "In the next notebook, we'll analyze the power-law properties of flare energy distributions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goesflareenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
